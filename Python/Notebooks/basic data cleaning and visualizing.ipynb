{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import networkx as nx\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/18565/Desktop/Classes/VA/Project/Code/VA-Project/data/Lekagul Sensor Data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>car-id</th>\n",
       "      <th>car-type</th>\n",
       "      <th>gate-name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>171477</td>\n",
       "      <td>171477</td>\n",
       "      <td>171477</td>\n",
       "      <td>171477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>170298</td>\n",
       "      <td>18708</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-07-31 12:00:02</td>\n",
       "      <td>20154519024544-322</td>\n",
       "      <td>1</td>\n",
       "      <td>general-gate7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>281</td>\n",
       "      <td>67698</td>\n",
       "      <td>16119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp              car-id car-type      gate-name\n",
       "count                171477              171477   171477         171477\n",
       "unique               170298               18708        7             40\n",
       "top     2015-07-31 12:00:02  20154519024544-322        1  general-gate7\n",
       "freq                      5                 281    67698          16119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index(\"Timestamp\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(df):\n",
    "    r\"\"\"retruns dictionary with keys data, edges and nodes \n",
    "        args:\n",
    "        df (pd.DataFrame) : Lekagul Sensor Data \n",
    "    \"\"\"\n",
    "    pbar = tqdm(total=len(df))\n",
    "    pbar.set_description(\"Data Processing :\")\n",
    "\n",
    "    car_ids = np.unique(df['car-id'])\n",
    "    data_dic = {\"data\":[],\"edges\":None}\n",
    "    data_dic[\"nodes\"] = list(np.unique(df['gate-name']))\n",
    "    all_edge_names = []\n",
    "    for car_id in car_ids:\n",
    "        row_data = {'car-id':car_id,'path_taken':[]}\n",
    "        car_data = df[df['car-id']==car_id]\n",
    "        row_data[\"car_type\"] = np.unique(car_data['car-type'])[0]\n",
    "        row_data['enter_date'] = str(car_data.index[0])\n",
    "        row_data['exit_date'] = str(car_data.index[-1])\n",
    "        total_time = car_data.index[-1]-car_data.index[0]\n",
    "        total_time = total_time.total_seconds()/60\n",
    "        row_data['total_in_time'] = round(total_time,2)\n",
    "        for ind in range(1,len(car_data)):\n",
    "            dic_key =car_data['gate-name'].iloc[ind-1]+ \" to \" +car_data['gate-name'].iloc[ind]\n",
    "            delta = car_data.index[ind]-car_data.index[ind-1]\n",
    "            delta = delta.total_seconds()/60\n",
    "            \n",
    "            row_data['path_taken'].append({dic_key:round(delta,2)})\n",
    "            if dic_key not in all_edge_names:\n",
    "                all_edge_names.append(dic_key)\n",
    "        data_dic[\"data\"].append(row_data)\n",
    "        pbar.update(len(car_data))\n",
    "    data_dic['edges'] =  all_edge_names\n",
    "    pbar.close()\n",
    "    return data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Processing :: 100%|██████████| 171477/171477 [03:53<00:00, 733.18it/s] \n"
     ]
    }
   ],
   "source": [
    "data_json = create_json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_cartype_data(data):\n",
    "    r\"\"\"returns data separated by cartype\n",
    "        Args:\n",
    "            Data (dictionary) : dic returned by create_json function\"\"\"\n",
    "    new_dic = {'1':[], '2':[], '2P':[], '3':[], '4':[], '5':[], '6':[]}\n",
    "    for one_car in data['data']:\n",
    "        new_dic[one_car['car_type']].append(one_car)\n",
    "        data['data'] = new_dic\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = seperate_cartype_data(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"w\") as outfile: \n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(data):\n",
    "    r\"\"\"returns normal and selfloop edges of a specific cartype\n",
    "        args:\n",
    "            data (dictionary) : dictionary data of a specific cartype\"\"\"\n",
    "    edges = {\"normal\":{},\"selfloop\":{}}\n",
    "    for car in data:\n",
    "        for path in car['path_taken']:\n",
    "            for key in path.keys():\n",
    "                if (key.split(\" \")[0]!=key.split(\" \")[2]):\n",
    "                    if key in edges['normal'].keys():\n",
    "                        edges['normal'][key] += path[key]\n",
    "                    else:\n",
    "                        edges['normal'][key] = path[key]\n",
    "                else:\n",
    "                    if key in edges['selfloop'].keys():\n",
    "                        edges['selfloop'][key] += path[key]\n",
    "                    else:\n",
    "                        edges['selfloop'][key] = path[key]\n",
    "                    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = get_edges(data_json['data']['1']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edge_weights = preprocessing.normalize(np.array(list(all_edges['normal'].values())).reshape(1,len(list(all_edges['normal'].values()))))\n",
    "sl_edge_weights = preprocessing.normalize(np.array(list(all_edges['selfloop'].values())).reshape(1,len(list(all_edges['selfloop'].values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edge_names = [(key.split(\" \")[0],key.split(\" \")[2]) for key in all_edges['normal'].keys()]\n",
    "sl_edge_names = [(key.split(\" \")[0],key.split(\" \")[2]) for key in all_edges['selfloop'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
